{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with NetCDF files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common file formats within environmental science is NetCDF ([Network Common Data Form](https://www.unidata.ucar.edu/software/netcdf/)). \n",
    "\n",
    "This format allows for storage of multiple variables, over multiple dimensions (i.e. N-dimensional arrays).   \n",
    "Files also contain the associated history and variable attributes. \n",
    "\n",
    "Example dataset format:  (from http://xarray.pydata.org/en/stable/data-structures.html)\n",
    "\n",
    "<br>\n",
    "<img src=\"../figures/dataset-diagram.png\">\n",
    "<br>\n",
    "\n",
    "\n",
    "If you're not familiar with NetCDF, and would like to know more, there is a bit more general information at the bottom of this notebook.  \n",
    "\n",
    "For now, we'll simply focus on how to access and work with these files in python ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF in python\n",
    "\n",
    "There are a few different packages that can be used to access data from NetCDF files.  \n",
    "These include: \n",
    "\n",
    "* [netCDF4](https://unidata.github.io/netcdf4-python/netCDF4/index.html)\n",
    "  * Core NetCDF package within python.  \n",
    "* [iris](https://scitools.org.uk/iris/docs/latest/index.html) \n",
    "  * Developed for earth system data. \n",
    "  * Data and metadata read into and stored within \"cubes\". \n",
    "* [xarray](http://xarray.pydata.org/en/stable/)\n",
    "  * A higher-level package, with a pandas-like interface for netCDF. \n",
    "  * What we'll focus on here today...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF4\n",
    "\n",
    "Contains everything you need to read/modify/create netCDF files. e.g. \n",
    "\n",
    "```python\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "\n",
    "openfile = Dataset('../data/cefas_GETM_nwes.nc4')\n",
    "bathymetry = openfile.variables['bathymetry'][:]\n",
    "```\n",
    "\n",
    "Variables are read into NumPy arrays (masked arrays if missing values specified). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray\n",
    "\n",
    "\n",
    "* Alternative to plain netCDF4 access from python. \n",
    "\n",
    "* Brings the power of pandas to environmental sciences, by providing N-dimensional variants of the core pandas data structures.\n",
    "  * Worth using for N-dimensional data, even when not reading netCDF files?\n",
    "\n",
    "| Pandas | xarray  |\n",
    "|---|---|\n",
    "| 1-D Series  | DataArray  |\n",
    "| DataFrame  | Dataset  |\n",
    "\n",
    "DataArray uses names for each dimension, making it easier to track than by just using axis numbers. \n",
    "\n",
    "For example, if you want to average your DataArray (da) over time, it is possible to write `da.mean(dim='time')`  \n",
    "You don't have to remember the index of the time axis.\n",
    "\n",
    "Compare:\n",
    "```python\n",
    "# xarray style\n",
    ">>> da.sel(time='2018-01-12').max(dim='ensemble')\n",
    "\n",
    "# standard numpy style\n",
    ">>> array[3, :, :].max(axis=2)\n",
    "```\n",
    "\n",
    "Without xarray, you need to first check which row refers to `time='2018-01-12'`, and which dimension is relevant for the ensemble. \n",
    "\n",
    "In the NumPy example, these choices are also not obvious to anyone reading the code at a later date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The main advantages of using xarray versus plain netCDF4 are:\n",
    "\n",
    "* intelligent selection along labelled dimensions (and also indices)\n",
    "* [groupby operations](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.groupby.html)\n",
    "* data alignment across named axes\n",
    "* IO (netcdf)\n",
    "  * Attributes/metadata held with the dataset. \n",
    "* conversion from and to Pandas.DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray as Pandas for N dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything that we are going to need... but not more\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_s = pd.Series(range(3), index=list('abc'))\n",
    "print(pd_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 1D series to ND aware DataArray \n",
    "da = xr.DataArray(pd_s)\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert 2D DataFrame to ND aware Dataset\n",
    "df = pd.DataFrame.from_dict({'A': [1, 2, 3], 'B': [4, 5, 6]},                         \n",
    "                             orient='index', columns=['one', 'two', 'three'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset.from_dataframe(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Let's open a netCDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray allows you to open both local and remote datasets. \n",
    "\n",
    "Remote datasets can be accessed through [OpenDAP](http://xarray.pydata.org/en/stable/io.html#opendap), allowing you to download (and subset) data available online.  \n",
    "e.g. you can access ocean colour data directly into python (from dataset acccessible online [here](earthdata.nasa.gov/collaborate/open-data-services-and-software/api/opendap/opendap-servers)):   \n",
    "```python\n",
    "remote_data = xr.open_dataset(\n",
    "      'https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/2020/176/A2020176.L3m_DAY_CHL_chlor_a_9km.nc')\n",
    "\n",
    "``` \n",
    "\n",
    "\n",
    "Here we'll use a file available locally on your machine (find in your data folder): `cefas_GETM_nwes.nc4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM = xr.open_dataset('../data/cefas_GETM_nwes.nc4')\n",
    "GETM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract information on the dimensions, coordinates and attributes of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dimensions\n",
    "GETM.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates\n",
    "print(type(GETM.coords['latc']))\n",
    "GETM.coords['latc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List name of dataset attributes\n",
    "GETM.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List variables\n",
    "#GETM.data_vars\n",
    "for var in GETM.data_vars: \n",
    "   print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = GETM['temp']\n",
    "print(temp.shape)\n",
    "temp\n",
    "\n",
    "# Can also use: \n",
    "# GETM.temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check variable attributes, in the same way we access DataSet attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.attrs)\n",
    "print('Variable {} has units {}'.format(temp.attrs['long_name'], temp.attrs['units']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be subset using standard indexing methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0, 0, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the DataArray subset keeps track of the associated coordinates, as well as other attributes. \n",
    "\n",
    "Behind the scense, data values are still stored as NumPy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(temp.values))\n",
    "temp.values[0, 0, 90, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Xarray Indexing and selecting data\n",
    "\n",
    "Xarray offers a variety of ways to subset your data. \n",
    "\n",
    "From http://xarray.pydata.org/\n",
    "<br>\n",
    "<img src=\"../figures/xarray_indexing_table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsets of our temperature variable, `temp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positional by integer\n",
    "print( temp[0, 2, :, :].shape )\n",
    "temp.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional by label (coordinate value)\n",
    "print( temp.loc['1996-02-02T01:00:00', 6, :, :].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by name and integer - note that we use round brackets here\n",
    "print( temp.isel(level=1, latc=90, lonc=100).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by name and label\n",
    "print( temp.sel(time='1996-02-02T01:00:00').shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using axes names, it's also possible to make a subset of an entire Dataset (across all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM.sel(time='1996-02-02T01:00:00', level=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define selection using nearest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In examples above, you use the coordinate values to make the selection by label. \n",
    "\n",
    "If the value you want doesn't exist, it is possible to interpolate e.g. to the nearest index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sel(level=2, lonc=-5.0, latc=50.0, method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tolerance limits can set for \"nearest\" coordinate values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. latc=-50 should not yield data\n",
    "\n",
    "lat = -50\n",
    "limit = 0.5\n",
    "\n",
    "try:\n",
    "    print(temp.sel(level=1, lonc=-5.0, latc=lat, method='nearest', tolerance=limit))\n",
    "except KeyError:\n",
    "    print(f'ERROR: {lat} outside tolerance of {limit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Other `method` options available are: \n",
    "* `backfill` / `bfill` - propagate values backward\n",
    "* `pad` / `ffill` - propagate values forward\n",
    "* `None` - default, exact matches only\n",
    "\n",
    "More information can be found in the xarray docs [here](http://xarray.pydata.org/en/stable/indexing.html). \n",
    "\n",
    "You can also interpolate between values, as discussed [here](xarray.pydata.org/en/stable/interpolation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our GETM dataset (loaded above), can you extract the follow data for the ocean conditions off Great Yarmouth?  \n",
    "The coordinates here are 52.6 deg N, 1.75 deg E.\n",
    "\n",
    "a) the bathymetry (ocean depth)  \n",
    "\n",
    "b) the temperature profile (i.e. all levels) at the same location, on 1st February 1996? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: \n",
    "# Hint: can you match the latitude and longitude exactly, or do you need to find the nearest value? \n",
    "#a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Plotting is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray enables simple plotting, to easily view your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM['temp'].isel(time=0, level=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will automatically plot 2D shading or 1D lines, dependent on the shape of the DataArray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GETM.temp.sel(lonc=1.75, latc=52.6, level=1, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other plotting packages are still available\n",
    "\n",
    "You may still want to tailor plots to your own design e.g. creating figures for publication or presentation. \n",
    "\n",
    "For example, let's look an example with cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a general mapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def make_map(ds, var='', title=None, units=None):\n",
    "def make_map():\n",
    "    # create figure and axes instances\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    ax = fig.add_subplot(111, projection=ccrs.Stereographic(central_latitude=60))\n",
    "    ax.set_extent([-10, 15, 49, 60], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    gl = ax.gridlines(draw_labels=False)\n",
    "    \n",
    "    feature = cartopy.feature.NaturalEarthFeature(name='coastline',\n",
    "                                                  category='physical',\n",
    "                                                  scale='50m',\n",
    "                                                  edgecolor='0.5',\n",
    "                                                  facecolor='0.8')\n",
    "    ax.add_feature(feature)\n",
    "    return fig, ax\n",
    "\n",
    "make_map();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our chosen data on the map, and use attributes to create annotate the figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract our chosen data and coordinates\n",
    "latc = GETM.coords['latc']\n",
    "lonc = GETM.coords['lonc']\n",
    "\n",
    "var = GETM['temp'].sel(time='1996-02-02T01:00:00', level=21)\n",
    "\n",
    "# Create the figure (using function above)\n",
    "fig, ax = make_map()\n",
    "\n",
    "# draw filled contours onto the map axes (ax).\n",
    "h = ax.contourf(lonc, latc, var, 50, cmap=plt.cm.coolwarm, transform=ccrs.PlateCarree())\n",
    "\n",
    "# add colorbar.\n",
    "cbar = fig.colorbar(h)\n",
    "# with unit label\n",
    "cbar.set_label(var.units)\n",
    "\n",
    "# add a title\n",
    "ax.set_title(f'A slice of {var.long_name}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Aside: Choice of colormaps\n",
    "\n",
    "The \"default\" colormap in python is viridis. However, colormaps can (and should) be varied to suit the data being shown.  \n",
    "For example, you would likely prefer a *sequential* scale for bathymetry, as opposed to a *diverging* scale for rainfall anomalies? \n",
    "\n",
    "There is a large variety of maps to choose from in matplotlib, as shown [here](https://matplotlib.org/2.0.1/users/colormaps.html). \n",
    "\n",
    "**You should always choose *perceptually uniform* shading to ensure that data is not misrepresented.**\n",
    "\n",
    "There are a large number of articles to explaing why you should avoid using rainbow/jet e.g.    \n",
    "* [The end of the rainbow](http://www.climate-lab-book.ac.uk/2014/end-of-the-rainbow/)\n",
    "* [A dangerous rainbow: Why colormaps matter](https://blogs.mathworks.com/headlines/2018/10/10/a-dangerous-rainbow-why-colormaps-matter/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can work with DataArrays in the same way as a NumPy array.  \n",
    "\n",
    "Benefit here is that calculations using DataArrays will give a result that is also a DataArray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = GETM['temp'].isel(time=0, level=4)\n",
    "bottom = GETM['temp'].isel(time=0, level=0)\n",
    "\n",
    "diff = top - bottom\n",
    "\n",
    "print(type(diff))\n",
    "diff.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available methods and statistics\n",
    "\n",
    "Methods available in pandas, are also available in xarray.  \n",
    "\n",
    "When performing calculations, can refer to dimensions by name or axis number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over time (using axis number)\n",
    "time_ave = GETM['temp'].mean(axis=0) \n",
    "print(time_ave.shape)\n",
    "\n",
    "# average over time and level (vertical)\n",
    "timelev_ave = GETM['temp'].mean(['time','level'])\n",
    "timelev_ave.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over time and longitude \n",
    "# i.e. zonal average (meridional section)\n",
    "timelon_ave = GETM['temp'].mean(['time','lonc']).isel(level=4)\n",
    "timelon_ave.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset can easily be saved to a new netCDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataset, containing just the average temperature, over time and level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the dataset, average over axes: \n",
    "ds_temp = GETM[['temp']].mean('time','level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to netcdf\n",
    "ds_temp.to_netcdf('../data/temp_avg_level_time.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the extra brackets used to extract the temperature variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When variable names are passed in a list, this produces a new Dataset:\n",
    "print(type( GETM[['temp']]) )\n",
    "\n",
    "# Passing just a string extracts the variable into a DataArray\n",
    "print(type( GETM['temp'])   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our GETM dataset again, we want to investigate the variability of temperature with depth across the seabed.  \n",
    "\n",
    "a) Extract bathymetry from the dataset. \n",
    "\n",
    "b) Extract temperature at the seabed (level index = 0), and average over time. \n",
    "\n",
    "c) Produce a scatter plot of depth (bathymetry) vs. seabed temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: \n",
    "# a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bonus Exercise\n",
    "\n",
    "For those who have finished the exercises above, and want more... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we mentioned that you can also access remote data sets online. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data = xr.open_dataset(\n",
    "      'https://oceandata.sci.gsfc.nasa.gov:443/opendap/MODISA/L3SMI/2020/176/A2020176.L3m_DAY_CHL_chlor_a_9km.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this remote dataset: \n",
    "    \n",
    "a) Extract the chlorophyll concentration, covering just the North Sea (or another region of your choice).\n",
    "\n",
    "b) Plot a map to show your result - check you've made a subset of the right region!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: \n",
    "# a) \n",
    "# Hint: You will need to extract the relevant variable over a range of latitude and londitude values.\n",
    "#  * Find the relevant variable name to extract from the data set. \n",
    "#  * Extract coordinate values if needed?\n",
    "#  * Subset over your chose range of latitude and longitude. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "# Note: data is only downloaded when you make the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "# More on the netCDF file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "* netCDF is a collection of formats for storing arrays\n",
    "* popular scientific file format for gridded datasets\n",
    "\n",
    "    * netCDF classic\n",
    "        * more widespread\n",
    "        * 2 GB file limit (if you don't use the unlimited dimension)\n",
    "        * often preffered for distributing products\n",
    "\n",
    "    * netCDF 64 bit offset\n",
    "        * supports larger files\n",
    "\n",
    "    * NetCDF4\n",
    "        * based on HDF5\n",
    "        * compression\n",
    "        * multiple unlimited variables\n",
    "        * new types inc. user defined\n",
    "        * herarchical groups\n",
    "                \n",
    "\n",
    "* Developed by Unidata-UCAR with the aim of storing climate model data (3D+time)\n",
    "* Auxilary information about each variable can be added\n",
    "* Readable text equivalent called CDL (use ncdump/ncgen)\n",
    "* Can be used with Climate and Forecast (CF) data convention\n",
    "http://cfconventions.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data model\n",
    "\n",
    "* Dimensions:describe the axes of the data arrays.\n",
    "* Variables: N-dimensional arrays of data.\n",
    "* Attributes: annotate variables or files with small notes or supplementary metadata.\n",
    "\n",
    "Example for an ocean model dataset:\n",
    "\n",
    "* Dimensions\n",
    "    * lat\n",
    "    * lon\n",
    "    * depth\n",
    "    * time\n",
    "* Variable\n",
    "    * Temperature\n",
    "    * Salinity\n",
    "    \n",
    "    \n",
    "* Global Attibutes\n",
    "    * Geographic grid type\n",
    "    * History\n",
    "\n",
    "* Variable attributes (Temperature)\n",
    "    * Long_name: \"sea water temperature\" \n",
    "    * Missing_value: 1.09009E36\n",
    "    * Units: deg. C\n",
    "    * range: -2:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for working with netCDF files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readable by many software tools\n",
    "\n",
    "NetCDF can be read by many different software tools e.g. ArcGIS, QGIS, Surfer, Ferret, Paraview etc.\n",
    "\n",
    "It can also be read by many different languages (one of the key motivations behind its use). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C and Fortran libraries\n",
    "\n",
    "These are used to underpin interfaces to other languages such as python (e.g. python package netCDF4)\n",
    "\n",
    "Include in these are ncdump/ncgen software, used to convert to and from human-readable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nco tools \n",
    "\n",
    "An *extremely useful* set of tools, to process netCDF files directly from the command line. \n",
    "\n",
    "For example, files can be subset, concatenated, averaged, or variables processed with simple arithmetic. \n",
    "\n",
    "Full documentation, showing the wide range of functionality, can be found here: http://nco.sourceforge.net/nco.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cdo tools\n",
    "Another powerful command line tool: https://code.mpimet.mpg.de/projects/cdo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick viewers?\n",
    "\n",
    "To view the file contents quickly and easily (without reading into python or elsewhere), there are a few different options.\n",
    "\n",
    "e.g. ncdump, ncview, panoply, pyncview, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ncdump\n",
    "\n",
    "This program should be available through your python installation, and is a useful way to quickly check the contents or attributes of a netCDF file.  \n",
    "\n",
    "You can peek inside your netcdf file from the prompt window (or terminal) using `ncdump -h <filename>` \n",
    "\n",
    "Be sure to use the `-h` option, otherwise it will literally dump the entire contents of your file into the screen in front of you (not what you normally want!).\n",
    "\n",
    "e.g.: \n",
    "\n",
    "```\n",
    "$ ncdump -h data/cefas_GETM_nwes.nc4\n",
    "netcdf cefas_GETM_nwes {\n",
    "dimensions:\n",
    "        latc = 360 ;\n",
    "        lonc = 396 ;\n",
    "        time = UNLIMITED ; // (6 currently)\n",
    "        level = 5 ;\n",
    "variables:\n",
    "        double bathymetry(latc, lonc) ;\n",
    "                bathymetry:units = \"m\" ;\n",
    "                bathymetry:long_name = \"bathymetry\" ;\n",
    "                bathymetry:valid_range = -5., 4000. ;\n",
    "                bathymetry:_FillValue = -10. ;\n",
    "                bathymetry:missing_value = -10. ;\n",
    "        float h(time, level, latc, lonc) ;\n",
    "                h:units = \"m\" ;\n",
    "                h:long_name = \"layer thickness\" ;\n",
    "                h:_FillValue = -9999.f ;\n",
    "                h:missing_value = -9999.f ;\n",
    "        double latc(latc) ;\n",
    "                latc:units = \"degrees_north\" ;\n",
    "        double level(level) ;\n",
    "                level:units = \"level\" ;\n",
    "        double lonc(lonc) ;\n",
    "                lonc:units = \"degrees_east\" ;\n",
    "        float temp(time, level, latc, lonc) ;\n",
    "                temp:units = \"degC\" ;\n",
    "                temp:long_name = \"temperature\" ;\n",
    "                temp:valid_range = -2.f, 40.f ;\n",
    "                temp:_FillValue = -9999.f ;\n",
    "                temp:missing_value = -9999.f ;\n",
    "        double time(time) ;\n",
    "                time:long_name = \"time\" ;\n",
    "                time:units = \"seconds since 1996-01-01 00:00:00\" ;\n",
    "...\n",
    "                \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* xarray [docs](http://xarray.pydata.org/en/stable/) \n",
    "* netCDF4 [docs](https://unidata.github.io/netcdf4-python/netCDF4/index.html)\n",
    "* Stephan Hoyer's [ECMWF talk](https://docs.google.com/presentation/d/16CMY3g_OYr6fQplUZIDqVtG-SKZqsG8Ckwoj2oOqepU/edit#slide=id.g2b68f9254d_1_27)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
